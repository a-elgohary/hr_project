{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZN9QOUnTh7aSWFPN5BC8E"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Providing data-driven suggestions for HR\n",
        "# Google Advanced Data Analytics Capstone\n",
        "## By: Abdullah El-Gohary\n",
        "---\n",
        "## Table of Contents:\n",
        "\n",
        "1. [Introduction](#'1')\n",
        "2. [Data Loading and Preparation](#'2')\n",
        "3. [Exploratory Data Analysis](#cell-id)\n",
        "4. Model Selection\n",
        "5. Model Construction</a></li>\n",
        "6. Confirm Model Assumptions</a></li>\n",
        "7. Summary of model results</a></li>\n",
        "8. Summary of model results</a></li>\n",
        "9. Conclusion, Recommendations, Next Steps</a></li>   \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4GThRQHHSRwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"'1'\"></a>\n",
        "# Introduction"
      ],
      "metadata": {
        "id": "7FDpFNr_ea-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the Company\n",
        "Salifort Motors is a ***fictional*** French-based manufacturer specializing in alternative energy vehicles. With a global workforce of over 100,000 employees, the company is engaged in the research, design, construction, validation, and distribution of electric, solar, algae, and hydrogen-based vehicles.\n",
        "\n",
        "### The Business Case\n",
        "The senior leadership team at Salifort Motors has assigned us the task of analyzing data to generate strategies for enhancing employee retention. As part of this initiative, they are interested in developing a model that can predict whether an employee is likely to leave the company. The primary question posed by the HR department at Salifort Motors is: What factors are likely to influence an employee's decision to leave the company?\n",
        "\n",
        "### The Goal of this Project\n",
        "**The objective of this project is to analyze the data collected by the HR department and build a predictive model that can determine if an employee is likely to leave the company.**\n",
        "\n",
        "By predicting which employees are likely to quit, we may be able to identify contributing factors to their departure. Given that finding, interviewing, and hiring new employees is both time-consuming and costly, enhancing employee retention will be advantageous for the company."
      ],
      "metadata": {
        "id": "qwKi3qn4zKlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"'2'\"></a>\n",
        "# Data Loading and Preparation"
      ],
      "metadata": {
        "id": "Q78zTyXvrAqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Dictionary"
      ],
      "metadata": {
        "id": "K_4GADGbAMLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Variable  |Description |\n",
        "-----|-----|\n",
        "satisfaction_level|Employee-reported job satisfaction level [0&ndash;1]|\n",
        "last_evaluation|Score of employee's last performance review [0&ndash;1]|\n",
        "number_project|Number of projects employee contributes to|\n",
        "average_monthly_hours|Average number of hours employee worked per month|\n",
        "time_spend_company|How long the employee has been with the company (years)\n",
        "Work_accident|Whether or not the employee experienced an accident while at work\n",
        "left|Whether or not the employee left the company\n",
        "promotion_last_5years|Whether or not the employee was promoted in the last 5 years\n",
        "Department|The employee's department\n",
        "salary|The employee's salary (U.S. dollars)\n",
        "\n",
        "For more information about the data, refer to its source on [Kaggle](https://www.kaggle.com/datasets/mfaisalqureshi/hr-analytics-and-job-prediction?select=HR_comma_sep.csv)."
      ],
      "metadata": {
        "id": "NOzOGRJiBd4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages and Load the dataset"
      ],
      "metadata": {
        "id": "bxD3WGr68OhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None) # to display all columns\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning - Model selection and evaluation\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Machine Learning - Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier, XGBRegressor, plot_importance\n",
        "\n",
        "# Saving Models\n",
        "import pickle"
      ],
      "metadata": {
        "id": "duIZfkX37s45"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset"
      ],
      "metadata": {
        "id": "hHTTKqe08ll_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to GitHub repo\n",
        "!\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "df_original = pd.read_csv(\"/content/drive/MyDrive/colab_notebooks/salifort_motors/hr_data.csv\")\n",
        "\n",
        "# Create a copy for data manipulation\n",
        "df = df_original.copy()\n",
        "\n",
        "# Display the first rows of 'df'\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "1FoyNyDz8kIg",
        "outputId": "824d7a7b-5913-4c98-86d0-8a2a73d39a20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1d3d5439d35c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/colab_notebooks/salifort_motors/hr_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a copy for data manipulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_original\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/colab_notebooks/salifort_motors/hr_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning and preprocessing"
      ],
      "metadata": {
        "id": "-wr5l_4zHJWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Gather basic information about the data\n",
        "df.info()"
      ],
      "metadata": {
        "id": "bVDAyLPE92zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no Missing Values"
      ],
      "metadata": {
        "id": "QHKhyYzi_mvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standarizing columns names"
      ],
      "metadata": {
        "id": "2-xiha1r_yOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List 'df' columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "_aPEI8KnCchG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dict. of columns to be renamed\n",
        "rename_cols = {'satisfaction_level': 'satisfaction', # made more consice\n",
        "               'last_evaluation': 'evaluation', # made more consice\n",
        "               'number_project': 'n_projects', # made more consice\n",
        "               'average_montly_hours': 'average_monthly_hours', #corrected spelling\n",
        "               'time_spend_company': 'tenure', # made more consice\n",
        "               'Work_accident': 'work_accident', # made snake_case\n",
        "               'promotion_last_5years': 'promotion_5y', # made more consice\n",
        "               'Department': 'department', # made snake_case\n",
        "               }\n",
        "\n",
        "# Renaming columns\n",
        "df.rename(columns= rename_cols, inplace= True)\n",
        "\n",
        "# confirming change\n",
        "df.columns"
      ],
      "metadata": {
        "id": "Y7pomhGW_KvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for duplicates"
      ],
      "metadata": {
        "id": "_h9EIJuOIwT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "_YqQ67G3I9f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Archive duplicates for record-keeping and future reference.\n",
        "df_duplicates = df[df.duplicated()].copy()\n",
        "\n",
        "# Drop duplicates\n",
        "df = df.drop_duplicates(keep = 'first')\n",
        "\n",
        "# Check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "goJZUKz-JKrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"cell-id\"></a>\n",
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "C9k-FZ0dqM9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier Detection"
      ],
      "metadata": {
        "id": "Yybog6Eshcs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be constructing a box plot to provide a comprehensive understanding of potential outliers within the data.\\\n",
        "This visualization technique will provide us with a high-level overview of the data distribution."
      ],
      "metadata": {
        "id": "sH2mVDpFiSnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ZDCjecryiuYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of quantitative columns\n",
        "quant_cols = ['satisfaction', 'evaluation', 'n_projects',\n",
        "              'average_monthly_hours', 'tenure'\n",
        "              ]\n",
        "# Create a new DataFrame of quantitative columns\n",
        "df_quant = df[quant_cols]\n",
        "df_quant.head()"
      ],
      "metadata": {
        "id": "ci7_jNvEiT5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# fit the scaler to the data and transform it\n",
        "df_quant_scaled = pd.DataFrame(scaler.fit_transform(df_quant),\n",
        "                             columns = df_quant.columns)\n",
        "\n",
        "# Create a boxplot to visualize distribution of `tenure` and detect any outliers\n",
        "plt.figure(figsize = (8,4))\n",
        "\n",
        "sns.boxplot(data = df_quant_scaled);\n",
        "plt.title('Quantitative Columns Boxplots');"
      ],
      "metadata": {
        "id": "2gE__W4tlFrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that ‘tenure’ is the sole column presenting outliers. We’re going to look into this more. But generally, it’s normal for some employees to have worked at the company longer than others. This can explain why we see these outliers."
      ],
      "metadata": {
        "id": "NPT_iRIlnEnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detecting outliers using interquartile range (IQR) method"
      ],
      "metadata": {
        "id": "AveCEiokquCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iqr_outliers(df, col, iqr_factor):\n",
        "    \"\"\"\n",
        "    This function returns a new Dataframe that only includes outliers\n",
        "    using the interquartile range (IQR) method\n",
        "    ---\n",
        "    Parameters:\n",
        "    ---\n",
        "    df (DataFrame)    : The input Dataframe\n",
        "    col (str)         : The name of the selected column\n",
        "    iqr_factor (float): The factor to multiply the IQR by to determine\n",
        "    the bounds of the outlier\n",
        "    \"\"\"\n",
        "    # Calculate the first (Q1) and third (Q3) quartiles\n",
        "    lower_quantile = df[col].quantile(0.25)\n",
        "    upper_quantile = df[col].quantile(0.75)\n",
        "\n",
        "    # Calculate Interquartile range\n",
        "    iqr = upper_quantile - lower_quantile\n",
        "\n",
        "    # Calculate the lower and the upper limit for outliers\n",
        "    lower_limit = lower_quantile - iqr_factor * iqr\n",
        "    upper_limit = upper_quantile + iqr_factor * iqr\n",
        "\n",
        "    outliers = df[(df[col] > upper_limit) | (df[col] < lower_limit)]\n",
        "\n",
        "    print('Upper Limit: {}'.format(upper_limit))\n",
        "    print('Lower Limit: {}'.format(lower_limit))\n",
        "    print('Outliers Count: {}'.format(len(outliers)))\n",
        "    # Return a DataFrame containing only the outliers\n",
        "    return outliers"
      ],
      "metadata": {
        "id": "IGyggty6l85s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and save the outliers in the 'tenure' column\n",
        "tenure_outliers = iqr_outliers(df, 'tenure', 1.5)\n",
        "tenure_outliers.head()"
      ],
      "metadata": {
        "id": "QvwWzvgnrftc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have saved the outliers of the tenure column in the variable ‘tenure_outliers’. We will not take any further actions since we consider it normal for some employees to have worked more years than others."
      ],
      "metadata": {
        "id": "v_p77u6zsRVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descriptive Statistics"
      ],
      "metadata": {
        "id": "TIvvJHPwWWZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather descriptive statistics about the data\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "3Uj3WA8ZYkzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some insights from the descriptive statistics:\n",
        "\n",
        "1. **Satisfaction**: The average satisfaction level is approximately 0.63, with a standard deviation of 0.24. This indicates that ***satisfaction levels vary quite a bit*** among your data points. The minimum satisfaction level is 0.09 and the maximum is 1.0, showing a wide range of satisfaction levels.\n",
        "\n",
        "2. **Evaluation**: The average evaluation score is approximately 0.72, with a standard deviation of 0.17, indicating less variability than the satisfaction scores. However, there is still a considerable amount of variability as the scores do range from 0.36 to 1.0.\n",
        "\n",
        "3. **Number of Projects**: On average, individuals are handling around 4 projects (3.8 to be precise). The minimum number of projects someone is handling is 2 and the maximum is 7.\n",
        "\n",
        "4. **Average Monthly Hours**: Individuals work around 200 hours per month on average, with a standard deviation of approximately 49 hours, indicating ***significant variability*** in working hours. The minimum average monthly hours are 96 and the maximum is 310.\n",
        "\n",
        "5. **Tenure**: The average tenure is approximately 3.36 years, with a standard deviation of about 1.33 years, indicating variability in tenure lengths.\n",
        "\n",
        "6. **Work Accident**: About 15% of individuals have had a work accident.\n",
        "\n",
        "7. **Left**: About 16% of individuals have left.\n",
        "\n",
        "8. **Promotion in Last 5 Years**: Only about 1.7% of individuals received a promotion in the last five years."
      ],
      "metadata": {
        "id": "-HTSfqOba7xG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQeoIIarWjeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Univariate Analysis"
      ],
      "metadata": {
        "id": "805B3VNETOsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    - Outlier Detection\n",
        "        - Techniques to detect and handle outliers\n",
        "\n",
        "    - Univariate Analysis\n",
        "        - Distribution of individual variables\n",
        "\n",
        "    - Bivariate Analysis\n",
        "        - Relationship between pairs of variables\n",
        "\n",
        "    - Multivariate Analysis\n",
        "        - Interactions between multiple variables\n",
        "\n",
        "    - Correlation Analysis\n",
        "        - Correlation matrix and heatmap\n",
        "\n",
        "    - Feature Engineering\n",
        "        - Creating new features from existing ones\n",
        "\n",
        "    - Conclusion\n",
        "        - Key insights from the analysis\n",
        "        - Next steps for further analysis or model building\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B5I54-uKTIpv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jjSzxNZqbYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}